{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae5aac9-92b2-4267-a654-9c0531c58b75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U accelerate\n",
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install flash-attn --no-build-isolation\n",
    "!pip install -U deepeval\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476bd784-9480-4f8e-9e24-92fb342d9f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6006e2-9af4-42cc-a7cc-6dc46d546b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class gpt4(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer\n",
    "    ):\n",
    "        self.client = OpenAI(\n",
    "        api_key=\"sk-or-vv-cbc6ecefae2862b46fc6305099a9185e836364a7d4289be0d6f087bc14b2b210\", # ваш ключ в VseGPT после регистрации\n",
    "        base_url=\"https://api.vsegpt.ru/v1\",\n",
    "    )\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        messages = []\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        response_big = self.client.chat.completions.create(\n",
    "            model=\"openai/gpt-4o-mini\", \n",
    "            messages=messages,\n",
    "            temperature=0.2\n",
    "        )\n",
    "\n",
    "        #print(\"Response BIG:\",response_big)\n",
    "        response = response_big.choices[0].message.content\n",
    "        return response\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        #ВАЩЕ НЕ МЕНЯЙТЕ!!!!!!!!!!!\n",
    "        return \"Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a999817-2902-4b18-99a3-a3917351fead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('benchmark100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9264079d-96bd-46c1-8795-c58f9cca0837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('webhelp_dataset.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "if 'data' in data:\n",
    "    df = pd.DataFrame(data['data'])\n",
    "\n",
    "df = df[df.description.str.len() > 4]\n",
    "\n",
    "\n",
    "df['text'] = df['title'] + ' ' + df['description']\n",
    "\n",
    "texts_urls = df[['text', 'url']].drop_duplicates(subset='text', keep='first').reset_index(drop=True)\n",
    "corpus = list(texts_urls.text.values)\n",
    "urls = texts_urls.url.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5045ea9f-3a2b-4aa9-a5a1-00196dcf5355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('ideal_prompt_t_pro_4bit_contextual.json', 'r') as fl:\n",
    "    jsoned = json.loads(fl.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "888e1db2-1ccc-473c-a01f-f8827557b267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gptshka = gpt4('', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3306f267-7cd8-48aa-a0c0-c05274c1a81a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deepeval.metrics import AnswerRelevancyMetric, FaithfulnessMetric, HallucinationMetric\n",
    "from deepeval import evaluate\n",
    "from deepeval.metrics import  ContextualRelevancyMetric, ContextualRecallMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "ans_metric = AnswerRelevancyMetric(\n",
    "        threshold=0.7,\n",
    "        model=gptshka,\n",
    "        include_reason=False\n",
    "    )\n",
    "fai_metric = FaithfulnessMetric(\n",
    "        threshold=0.7,\n",
    "        model=gptshka,\n",
    "        include_reason=False,\n",
    "        truths_extraction_limit=5\n",
    "    )\n",
    "\n",
    "con_metric = ContextualRecallMetric(\n",
    "    threshold=0.7,\n",
    "    model=gptshka,\n",
    "    include_reason=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceab9ffe-05b3-46ac-9cae-afb3f91d69ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def _wrapper(chunks, corpus):\n",
    "    chunks_ = copy.deepcopy(chunks)\n",
    "    for j in range(len(chunks)):\n",
    "        chunks_[j] = f'Чанк {j+1}: {corpus[chunks[j]]}'\n",
    "    return '\\n'.join(chunks_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75c62e1-9862-442e-81b6-443f4747021e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Здесь считаете метрики, но за токенами следите пж\n",
    "\n",
    "\"\"\"\n",
    "import tqdm\n",
    "logs_ = []\n",
    "for i, row in tqdm.tqdm(train.iterrows()):\n",
    "    actual_output = jsoned[i]['output']\n",
    "    inp = train.loc[i, 'question']\n",
    "    expected_output = train.loc[i, 'target']\n",
    "    retrieval_context = [corpus[j] for j in jsoned[i]['chunks']]\n",
    "    test_case = LLMTestCase(\n",
    "        input=inp,\n",
    "        actual_output=actual_output,\n",
    "        expected_output=expected_output,\n",
    "        retrieval_context=retrieval_context\n",
    "    )\n",
    "    results = evaluate(\n",
    "        test_cases=[test_case],\n",
    "        metrics=[\n",
    "            ans_metric,\n",
    "            fai_metric,\n",
    "            con_metric\n",
    "        ]\n",
    "    )\n",
    "    logs_.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a700ae-c395-499d-bed9-64cd836c1305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "сейв логов\n",
    "\n",
    "\"\"\"\n",
    "logs__ = []\n",
    "\n",
    "for i, lg in enumerate(logs_):\n",
    "    ttt = []\n",
    "    for metr in lg.test_results[0].metrics_data:\n",
    "        ttt.append({\n",
    "            'MetricData': metr.name,\n",
    "            'score': metr.score,\n",
    "            'reason': metr.reason\n",
    "        })\n",
    "    logs__.append(ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fd58878-1b86-4292-b3dc-209c8278e212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_as_json(filename, data):\n",
    "    try:\n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(data, file, indent=4) \n",
    "        print(f\"Data successfully written to {filename}\")\n",
    "    except IOError as e:\n",
    "        print(f\"An error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d02b6f01-65bf-4cc3-b3a2-ac61794fed11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to t-pro_contextual_ragas.json\n"
     ]
    }
   ],
   "source": [
    "save_as_json('t-pro_contextual_ragas.json', logs__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
